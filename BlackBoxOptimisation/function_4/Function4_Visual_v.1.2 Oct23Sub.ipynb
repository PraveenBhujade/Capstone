{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "l87YfqG-ua5r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original candidates= (500, 4)\n",
      "Reduced candidates to 187 promising ones using SVM.\n",
      "Reduced candidates= (187, 4)\n",
      "first point ei_vals[ 114 ]= 7.436777577953034e-05\n",
      "seed_points=\n",
      " [[0.43757946 0.29761781 0.32066824 0.46207877]\n",
      " [0.41052034 0.51951044 0.37652583 0.48394103]\n",
      " [0.52324044 0.53865867 0.14377322 0.38207296]\n",
      " [0.30831895 0.51346782 0.26072472 0.39140407]\n",
      " [0.20390738 0.35335078 0.54331341 0.42765105]\n",
      " [0.5151553  0.30368405 0.1743839  0.48520396]\n",
      " [0.57228918 0.45529146 0.00894935 0.51918276]\n",
      " [0.08418963 0.45979589 0.55531764 0.56453929]\n",
      " [0.52720065 0.56488675 0.21461492 0.31862413]\n",
      " [0.57950358 0.37175205 0.11700239 0.52449857]]\n",
      "seed=\t [0.43757946 0.29761781 0.32066824 0.46207877] \tEI= 0.004553091474169764\n",
      "best_x=\t [0.38403796 0.41298835 0.39949583 0.43688922] \tEI= 0.004553091474169764\n",
      "seed=\t [0.41052034 0.51951044 0.37652583 0.48394103] \tEI= 0.004553091481979956\n",
      "best_x=\t [0.38404171 0.41299468 0.39949652 0.43689139] \tEI= 0.004553091481979956\n",
      "seed=\t [0.52324044 0.53865867 0.14377322 0.38207296] \tEI= 0.001922236801253449\n",
      "seed=\t [0.30831895 0.51346782 0.26072472 0.39140407] \tEI= 0.0019222344596541083\n",
      "seed=\t [0.20390738 0.35335078 0.54331341 0.42765105] \tEI= 0.004553091499625077\n",
      "best_x=\t [0.38404037 0.41299183 0.39949672 0.43689097] \tEI= 0.004553091499625077\n",
      "seed=\t [0.5151553  0.30368405 0.1743839  0.48520396] \tEI= 0.0019222367954219105\n",
      "seed=\t [0.57228918 0.45529146 0.00894935 0.51918276] \tEI= 2.664824246449924e-07\n",
      "seed=\t [0.08418963 0.45979589 0.55531764 0.56453929] \tEI= 2.586687453259444e-07\n",
      "seed=\t [0.52720065 0.56488675 0.21461492 0.31862413] \tEI= 1.8375858678790598e-07\n",
      "seed=\t [0.57950358 0.37175205 0.11700239 0.52449857] \tEI= 1.5029660807159593e-07\n",
      "Suggested next query point (raw input space): 0.384040-0.412992-0.399497-0.436891\n",
      "Expected Improvement at this point (normalized): 0.004553091499625077\n",
      "GP predicted mean at this point (original y scale): [0.28974963]\n",
      "GP predicted stddev at this point (original y scale): [0.26310654]\n",
      "This visualization works only for 2D input data.\n",
      "SVM visualisation works only for 2-D inputs.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel as C, WhiteKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load initial data\n",
    "# ------------------------------------------------------------\n",
    "X = np.load(\"initial_inputs.npy\")        # shape (n0, d)\n",
    "y = np.load(\"initial_outputs.npy\")       # shape (n0,)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Append new information\n",
    "# ------------------------------------------------------------\n",
    "X = np.append(X,[[0.440416, 0.425453, 0.378353, 0.397106]], axis=0)  # Append week1 inputs\n",
    "y = np.append(y, 0.2600760462416969)         # Append week1 outputs\n",
    "X = np.append(X,[[0.410011, 0.415254, 0.344451, 0.438807]], axis=0)  # Append week2 inputs\n",
    "y = np.append(y, 0.39833768922486756)          # Append week2 outputs\n",
    "\n",
    "# Save the updated data\n",
    "np.save(\"updated_inputs_PW2.npy\", X)\n",
    "np.save(\"updated_outputs_PW2.npy\", y)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Normalise inputs and outputs\n",
    "# ------------------------------------------------------------\n",
    "x_scaler = StandardScaler()\n",
    "Xn = x_scaler.fit_transform(X)\n",
    "\n",
    "y_mean = y.mean()\n",
    "y_std = y.std() if y.std() > 0 else 1.0\n",
    "yn = (y - y_mean) / y_std                 # GP works better with normalized target\n",
    "\n",
    "\n",
    "def visualize_iteration(Xn, seed_points, suggested_point):\n",
    "    \"\"\"\n",
    "    Simple 2D visualization of current iteration:\n",
    "    - Xn: existing normalized input data (n x 2)\n",
    "    - seed_points: candidate points used for local optimization (m x 2)\n",
    "    - suggested_point: final chosen query point (1 x 2)\n",
    "    \"\"\"\n",
    "    if Xn.shape[1] != 2:\n",
    "        print(\"This visualization works only for 2D input data.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(Xn[:, 0], Xn[:, 1], c='blue', label='Existing points', s=40, alpha=0.7)\n",
    "    plt.scatter(seed_points[:, 0], seed_points[:, 1], c='orange', label='Seed points', s=50, alpha=0.7, edgecolors='k')\n",
    "    plt.scatter(suggested_point[0], suggested_point[1], c='red', label='Suggested point', s=120, marker='*', edgecolors='k')\n",
    "\n",
    "    plt.title(\"Bayesian Optimization Progress (2D)\")\n",
    "    plt.xlabel(\"Feature 1 (normalized)\")\n",
    "    plt.ylabel(\"Feature 2 (normalized)\")\n",
    "    #plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_svm(Xn, yn, candidates_raw, good_candidates_raw,\n",
    "                  suggested_point, svm_clf, x_scaler):\n",
    "    \"\"\"\n",
    "    Plot the SVM decision boundary together with:\n",
    "      • all random candidates (gray)\n",
    "      • candidates kept by SVM (orange)\n",
    "      • existing data (blue)\n",
    "      • final suggestion (red star)\n",
    "    \"\"\"\n",
    "    if Xn.shape[1] != 2:\n",
    "        print(\"SVM visualisation works only for 2-D inputs.\")\n",
    "        return\n",
    "\n",
    "    # Create a dense grid for the contour\n",
    "    h = 0.01\n",
    "    x_min, x_max = Xn[:,0].min()-0.2, Xn[:,0].max()+0.2\n",
    "    y_min, y_max = Xn[:,1].min()-0.2, Xn[:,1].max()+0.2\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = svm_clf.decision_function(grid)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.figure(figsize=(9,7))\n",
    "    # Decision boundary\n",
    "    plt.contourf(xx, yy, Z, levels=[-np.inf,0,np.inf],\n",
    "                 colors=['#FFDDDD','#DDFFDD'], alpha=0.3)\n",
    "    plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='k')\n",
    "\n",
    "    # All random candidates\n",
    "    plt.scatter(candidates_raw[:,0], candidates_raw[:,1],\n",
    "                c='lightgray', s=15, alpha=0.6, label='All random candidates')\n",
    "\n",
    "    # Candidates kept by SVM\n",
    "    plt.scatter(good_candidates_raw[:,0], good_candidates_raw[:,1],\n",
    "                c='orange', s=40, edgecolor='k', label='SVM-filtered candidates')\n",
    "\n",
    "    # Existing points (colour-coded by class for reference)\n",
    "    median_y = np.median(yn)\n",
    "    colors = np.where(yn >= median_y, 'blue', 'cyan')\n",
    "    plt.scatter(Xn[:,0], Xn[:,1], c=colors, s=80,\n",
    "                edgecolor='k', label='Existing points (≥/ < median)')\n",
    "\n",
    "    # Suggested point\n",
    "    plt.scatter(suggested_point[0], suggested_point[1], c='red',\n",
    "                s=150, marker='*', edgecolor='k', label='Suggested point')\n",
    "\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.title(\"SVM Decision Boundary + Candidate Filtering\")\n",
    "    plt.xlabel(\"Feature 1 (norm.)\")\n",
    "    plt.ylabel(\"Feature 2 (norm.)\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Fit a Gaussian Process surrogate\n",
    "# ------------------------------------------------------------\n",
    "d = X.shape[1]\n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=np.ones(d),\n",
    "                                      length_scale_bounds=(1e-5, 1e5),\n",
    "                                      nu=2.5)\n",
    "kernel += WhiteKernel(noise_level=1e-6,\n",
    "                      noise_level_bounds=(1e-15, 1e1))\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              normalize_y=False,\n",
    "                              n_restarts_optimizer=10,\n",
    "                              random_state=0)\n",
    "gp.fit(Xn, yn)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Add SVM to classify promising regions\n",
    "# ------------------------------------------------------------\n",
    "if len(yn) > 1:  # need at least two points for classification\n",
    "    median_y = np.median(yn)\n",
    "    labels = (yn >= median_y).astype(int)\n",
    "    svm_clf = SVC(kernel='rbf', C=1.0)\n",
    "    svm_clf.fit(Xn, labels)\n",
    "else:\n",
    "    svm_clf = None\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Define Expected Improvement acquisition (for maximization)\n",
    "# ------------------------------------------------------------\n",
    "f_best = yn.max()\n",
    "xi = 0.01     # exploration parameter\n",
    "\n",
    "def predict_raw(x_raw):\n",
    "    \"\"\"Predict mean and std in normalized GP space for a raw input x_raw.\"\"\"\n",
    "    x = np.atleast_2d(x_raw)\n",
    "    xn = x_scaler.transform(x)\n",
    "    mu, sigma = gp.predict(xn, return_std=True)\n",
    "    return mu.ravel(), sigma.ravel()\n",
    "\n",
    "def expected_improvement_raw(x_raw, xi=xi):\n",
    "    \"\"\"Compute EI for a raw input x_raw.\"\"\"\n",
    "    mu, sigma = predict_raw(x_raw)\n",
    "    sigma = np.maximum(sigma, 1e-9)       # avoid division by zero\n",
    "    z = (mu - f_best - xi) / sigma\n",
    "    ei = (mu - f_best - xi) * norm.cdf(z) + sigma * norm.pdf(z)\n",
    "    #print (\"x_raw=\", x_raw, \"mu=\", mu, \"sigma=\", sigma,\"ei=\",ei)\n",
    "    return ei.ravel()[0]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Search for the next query point\n",
    "# ------------------------------------------------------------\n",
    "# Domain is assumed to be [0,1]^d (based on inspection of initial data)\n",
    "bounds = [(0.0, 1.0)] * d\n",
    "\n",
    "# Global random search to find good seeds\n",
    "n_seeds = 500\n",
    "rng = np.random.default_rng(1)\n",
    "# Need to decide where the random points needs to be\n",
    "candidates_raw = rng.uniform(0.0, 1.0, size=(n_seeds, d))\n",
    "\n",
    "\n",
    "print (\"Original candidates=\", candidates_raw.shape)\n",
    "good_candidates_raw = candidates_raw.copy()\n",
    "\n",
    "if svm_clf is not None:\n",
    "    candidates_n = x_scaler.transform(candidates_raw)\n",
    "    predicted_labels = svm_clf.predict(candidates_n)\n",
    "    good_idx = np.where(predicted_labels == 1)[0]\n",
    "    if len(good_idx) > 0:\n",
    "        good_candidates_raw = candidates_raw[good_idx]\n",
    "        print(f\"Reduced candidates to {len(good_candidates_raw)} promising ones using SVM.\")\n",
    "\n",
    "print (\"Reduced candidates=\", good_candidates_raw.shape)\n",
    "\n",
    "# ---- EI evaluation on the (possibly reduced) candidate set ----\n",
    "ei_vals = np.array([expected_improvement_raw(c) for c in good_candidates_raw])\n",
    "best_idx = np.argmax(ei_vals)\n",
    "print (\"first point ei_vals[\",best_idx,\"]=\", ei_vals[best_idx])\n",
    "\n",
    "# ---- Take top-10 seeds for local optimisation ----\n",
    "seed_points = good_candidates_raw[np.argsort(-ei_vals)[:10]]\n",
    "print (\"seed_points=\\n\", seed_points)\n",
    "\n",
    "best_x = None\n",
    "best_val = -1.0\n",
    "for s in seed_points:\n",
    "    res = minimize(lambda xx: -expected_improvement_raw(xx),\n",
    "                   x0=s,\n",
    "                   bounds=bounds,\n",
    "                   method=\"L-BFGS-B\",\n",
    "                   options={'maxiter':300})\n",
    "    if res.success:\n",
    "        val = -res.fun\n",
    "        print ( \"seed=\\t\", s, \"\\tEI=\", val)\n",
    "        #visualize_iteration(Xn, seed_points, best_x)\n",
    "        if val > best_val:\n",
    "            best_val = val\n",
    "            best_x = res.x.copy()\n",
    "            print ( \"best_x=\\t\", best_x, \"\\tEI=\", val )\n",
    "        \n",
    "        \n",
    "\n",
    "# Fallback if optimizer fails\n",
    "if best_x is None:\n",
    "    best_x = good_candidates_raw[best_idx]\n",
    "    best_val = ei_vals[best_idx]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Report results\n",
    "# ------------------------------------------------------------\n",
    "suggested_point = np.atleast_1d(best_x)\n",
    "mu_s, sigma_s = predict_raw(suggested_point.reshape(1, -1))\n",
    "\n",
    "# Convert mean/std back to original y-scale\n",
    "mu_orig = mu_s * y_std + y_mean\n",
    "sigma_orig = sigma_s * y_std\n",
    "next_query = \"-\".join([f\"{xi:.6f}\" for xi in suggested_point])\n",
    "\n",
    "print(\"Suggested next query point (raw input space):\", next_query)\n",
    "print(\"Expected Improvement at this point (normalized):\", best_val)\n",
    "print(\"GP predicted mean at this point (original y scale):\", mu_orig)\n",
    "print(\"GP predicted stddev at this point (original y scale):\", sigma_orig)\n",
    "\n",
    "# Visualise 1. Standard BO progress plot\n",
    "visualize_iteration(X, seed_points, best_x)\n",
    "\n",
    "# 2. SVM decision-boundary plot (only when SVM was trained)\n",
    "if svm_clf is not None:\n",
    "    visualize_svm(X, y,\n",
    "                  candidates_raw,\n",
    "                  good_candidates_raw,\n",
    "                  best_x,\n",
    "                  svm_clf,\n",
    "                  x_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
