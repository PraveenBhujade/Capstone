{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "l87YfqG-ua5r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 4)\n",
      "first point ei_vals[ 319 ]= 0.001230258972956342\n",
      "seed_points=\n",
      " [[0.43757946 0.29761781 0.32066824 0.46207877]\n",
      " [0.41052034 0.51951044 0.37652583 0.48394103]\n",
      " [0.5151553  0.30368405 0.1743839  0.48520396]\n",
      " [0.52324044 0.53865867 0.14377322 0.38207296]\n",
      " [0.30831895 0.51346782 0.26072472 0.39140407]\n",
      " [0.57950358 0.37175205 0.11700239 0.52449857]\n",
      " [0.57228918 0.45529146 0.00894935 0.51918276]\n",
      " [0.20390738 0.35335078 0.54331341 0.42765105]\n",
      " [0.30168325 0.26408328 0.33632744 0.4851419 ]\n",
      " [0.545335   0.36119173 0.05831303 0.5685933 ]]\n",
      "seed=\t [0.43757946 0.29761781 0.32066824 0.46207877] \tEI= 0.017663233848543063\n",
      "best_x=\t [0.41001063 0.41525382 0.34445024 0.43880716] \tEI= 0.017663233848543063\n",
      "seed=\t [0.41052034 0.51951044 0.37652583 0.48394103] \tEI= 0.01766323384619887\n",
      "seed=\t [0.5151553  0.30368405 0.1743839  0.48520396] \tEI= 0.017663233841799048\n",
      "seed=\t [0.52324044 0.53865867 0.14377322 0.38207296] \tEI= 0.01766323283587665\n",
      "seed=\t [0.30831895 0.51346782 0.26072472 0.39140407] \tEI= 0.01766323384842746\n",
      "seed=\t [0.57950358 0.37175205 0.11700239 0.52449857] \tEI= 0.017663233850197402\n",
      "best_x=\t [0.41001022 0.41525398 0.34445027 0.43880644] \tEI= 0.017663233850197402\n",
      "seed=\t [0.57228918 0.45529146 0.00894935 0.51918276] \tEI= 0.017663233749545624\n",
      "seed=\t [0.20390738 0.35335078 0.54331341 0.42765105] \tEI= 0.017663233839431948\n",
      "seed=\t [0.30168325 0.26408328 0.33632744 0.4851419 ] \tEI= 0.017663233850447428\n",
      "best_x=\t [0.41001062 0.4152536  0.34445109 0.43880654] \tEI= 0.017663233850447428\n",
      "seed=\t [0.545335   0.36119173 0.05831303 0.5685933 ] \tEI= 0.0176632338480799\n",
      "Suggested next query point (raw input space): 0.410011-0.415254-0.344451-0.438807\n",
      "Expected Improvement at this point (normalized): 0.017663233850447428\n",
      "GP predicted mean at this point (original y scale): [0.41414421]\n",
      "GP predicted stddev at this point (original y scale): [0.22298254]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel as C, WhiteKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load initial data\n",
    "# ------------------------------------------------------------\n",
    "X = np.load(\"initial_inputs.npy\")        # shape (n0, d)\n",
    "y = np.load(\"initial_outputs.npy\")       # shape (n0,)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Append new information\n",
    "# ------------------------------------------------------------\n",
    "X = np.append(X,[[0.440416, 0.425453, 0.378353, 0.397106]], axis=0)  # Append week1 inputs\n",
    "y = np.append(y, 0.2600760462416969)         # Append week1 outputs\n",
    "\n",
    "# Save the updated data\n",
    "np.save(\"updated_inputs_PW1.npy\", X)\n",
    "np.save(\"updated_outputs_PW1.npy\", y)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Normalise inputs and outputs\n",
    "# ------------------------------------------------------------\n",
    "x_scaler = StandardScaler()\n",
    "Xn = x_scaler.fit_transform(X)\n",
    "\n",
    "y_mean = y.mean()\n",
    "y_std = y.std() if y.std() > 0 else 1.0\n",
    "yn = (y - y_mean) / y_std                 # GP works better with normalized target\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Fit a Gaussian Process surrogate\n",
    "# ------------------------------------------------------------\n",
    "d = X.shape[1]\n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=np.ones(d),\n",
    "                                      length_scale_bounds=(1e-5, 1e5),\n",
    "                                      nu=2.5)\n",
    "kernel += WhiteKernel(noise_level=1e-6,\n",
    "                      noise_level_bounds=(1e-10, 1e1))\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              normalize_y=False,\n",
    "                              n_restarts_optimizer=10,\n",
    "                              random_state=0)\n",
    "gp.fit(Xn, yn)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Define Expected Improvement acquisition (for maximization)\n",
    "# ------------------------------------------------------------\n",
    "f_best = yn.max()\n",
    "xi = 0.01     # exploration parameter\n",
    "\n",
    "def predict_raw(x_raw):\n",
    "    \"\"\"Predict mean and std in normalized GP space for a raw input x_raw.\"\"\"\n",
    "    x = np.atleast_2d(x_raw)\n",
    "    xn = x_scaler.transform(x)\n",
    "    mu, sigma = gp.predict(xn, return_std=True)\n",
    "    return mu.ravel(), sigma.ravel()\n",
    "\n",
    "def expected_improvement_raw(x_raw, xi=xi):\n",
    "    \"\"\"Compute EI for a raw input x_raw.\"\"\"\n",
    "    mu, sigma = predict_raw(x_raw)\n",
    "    sigma = np.maximum(sigma, 1e-9)       # avoid division by zero\n",
    "    z = (mu - f_best - xi) / sigma\n",
    "    ei = (mu - f_best - xi) * norm.cdf(z) + sigma * norm.pdf(z)\n",
    "    #print (\"x_raw=\", x_raw, \"mu=\", mu, \"sigma=\", sigma,\"ei=\",ei)\n",
    "    return ei.ravel()[0]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Search for the next query point\n",
    "# ------------------------------------------------------------\n",
    "# Domain is assumed to be [0,1]^d (based on inspection of initial data)\n",
    "bounds = [(0.0, 1.0)] * d\n",
    "\n",
    "# Global random search to find good seeds\n",
    "n_seeds = 500\n",
    "rng = np.random.default_rng(1)\n",
    "candidates = rng.uniform(0.0, 1.0, size=(n_seeds, d))\n",
    "#Central limit theorm\n",
    "\n",
    "print (candidates.shape)\n",
    "ei_vals = np.array([expected_improvement_raw(c) for c in candidates])\n",
    "best_idx = np.argmax(ei_vals)\n",
    "print (\"first point ei_vals[\",best_idx,\"]=\", ei_vals[best_idx])\n",
    "\n",
    "# Take top few seeds for local optimisation\n",
    "seed_points = candidates[np.argsort(-ei_vals)[:10]]\n",
    "print (\"seed_points=\\n\", seed_points)\n",
    "\n",
    "best_x = None\n",
    "best_val = -1.0\n",
    "for s in seed_points:\n",
    "    res = minimize(lambda xx: -expected_improvement_raw(xx),\n",
    "                   x0=s,\n",
    "                   bounds=bounds,\n",
    "                   method=\"L-BFGS-B\",\n",
    "                   options={'maxiter':300})\n",
    "    if res.success:\n",
    "        val = -res.fun\n",
    "        print ( \"seed=\\t\", s, \"\\tEI=\", val)\n",
    "        #visualize_iteration(Xn, seed_points, best_x)\n",
    "        if val > best_val:\n",
    "            best_val = val\n",
    "            best_x = res.x.copy()\n",
    "            print ( \"best_x=\\t\", best_x, \"\\tEI=\", val )\n",
    "        \n",
    "        \n",
    "\n",
    "# Fallback if optimizer fails\n",
    "if best_x is None:\n",
    "    best_x = candidates[best_idx]\n",
    "    best_val = ei_vals[best_idx]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Report results\n",
    "# ------------------------------------------------------------\n",
    "suggested_point = np.atleast_1d(best_x)\n",
    "mu_s, sigma_s = predict_raw(suggested_point.reshape(1, -1))\n",
    "\n",
    "# Convert mean/std back to original y-scale\n",
    "mu_orig = mu_s * y_std + y_mean\n",
    "sigma_orig = sigma_s * y_std\n",
    "next_query = \"-\".join([f\"{xi:.6f}\" for xi in suggested_point])\n",
    "\n",
    "print(\"Suggested next query point (raw input space):\", next_query)\n",
    "print(\"Expected Improvement at this point (normalized):\", best_val)\n",
    "print(\"GP predicted mean at this point (original y scale):\", mu_orig)\n",
    "print(\"GP predicted stddev at this point (original y scale):\", sigma_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
