{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "l87YfqG-ua5r"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k1__k2__length_scale is close to the specified upper bound 10000000000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/gaussian_process/kernels.py:442: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-10. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 8)\n",
      "first point ei_vals[ 320 ]= 0.0005383917194791733\n",
      "seed_points=\n",
      " [[0.09265999 0.32537231 0.13255613 0.33445081 0.76733688 0.17134511\n",
      "  0.07414239 0.80773506]\n",
      " [0.1996495  0.40188013 0.11413416 0.56561133 0.72265224 0.68763408\n",
      "  0.00718758 0.9824687 ]\n",
      " [0.04080233 0.60917259 0.01175471 0.07830876 0.58317929 0.62059085\n",
      "  0.17053724 0.40322938]\n",
      " [0.24938085 0.3142001  0.18716287 0.22048043 0.66200035 0.2217289\n",
      "  0.18884683 0.27084396]\n",
      " [0.28350568 0.14855165 0.12436934 0.15309306 0.91614573 0.36875769\n",
      "  0.56695955 0.14701866]\n",
      " [0.48759449 0.06717532 0.07788443 0.77905051 0.89877285 0.95982724\n",
      "  0.07219385 0.25221874]\n",
      " [0.03687728 0.70421875 0.31575293 0.02268245 0.91261053 0.23637586\n",
      "  0.0934657  0.73823609]\n",
      " [0.40569727 0.19899599 0.10174264 0.06414533 0.5146915  0.00294365\n",
      "  0.39723145 0.06034025]\n",
      " [0.06840964 0.07994251 0.27178513 0.57635807 0.80544862 0.26719158\n",
      "  0.28317106 0.82448214]\n",
      " [0.19764459 0.03596475 0.00927308 0.36674591 0.19362442 0.50362833\n",
      "  0.13141981 0.62675898]]\n",
      "seed=\t [0.09265999 0.32537231 0.13255613 0.33445081 0.76733688 0.17134511\n",
      " 0.07414239 0.80773506] \tEI= 0.10301918452881643\n",
      "best_x=\t [0.12264765 0.15394315 0.16239289 0.04557844 1.         0.53667886\n",
      " 0.26083585 0.80773506] \tEI= 0.10301918452881643\n",
      "seed=\t [0.1996495  0.40188013 0.11413416 0.56561133 0.72265224 0.68763408\n",
      " 0.00718758 0.9824687 ] \tEI= 0.10301918516723378\n",
      "best_x=\t [0.12268536 0.15397914 0.16241523 0.04559259 1.         0.53666173\n",
      " 0.26083053 0.9824687 ] \tEI= 0.10301918516723378\n",
      "seed=\t [0.04080233 0.60917259 0.01175471 0.07830876 0.58317929 0.62059085\n",
      " 0.17053724 0.40322938] \tEI= 0.1030191862679738\n",
      "best_x=\t [0.12266176 0.15396918 0.1623983  0.04560372 1.         0.53666323\n",
      " 0.26082385 0.40322938] \tEI= 0.1030191862679738\n",
      "seed=\t [0.24938085 0.3142001  0.18716287 0.22048043 0.66200035 0.2217289\n",
      " 0.18884683 0.27084396] \tEI= 0.10301918250053228\n",
      "seed=\t [0.28350568 0.14855165 0.12436934 0.15309306 0.91614573 0.36875769\n",
      " 0.56695955 0.14701866] \tEI= 0.10301918596197014\n",
      "seed=\t [0.48759449 0.06717532 0.07788443 0.77905051 0.89877285 0.95982724\n",
      " 0.07219385 0.25221874] \tEI= 0.10301918709500162\n",
      "best_x=\t [0.12264065 0.15398015 0.16240872 0.0456052  1.         0.53666187\n",
      " 0.26082951 0.25221874] \tEI= 0.10301918709500162\n",
      "seed=\t [0.03687728 0.70421875 0.31575293 0.02268245 0.91261053 0.23637586\n",
      " 0.0934657  0.73823609] \tEI= 0.10301918691872163\n",
      "seed=\t [0.40569727 0.19899599 0.10174264 0.06414533 0.5146915  0.00294365\n",
      " 0.39723145 0.06034025] \tEI= 0.10301918610972377\n",
      "seed=\t [0.06840964 0.07994251 0.27178513 0.57635807 0.80544862 0.26719158\n",
      " 0.28317106 0.82448214] \tEI= 0.10301918346597963\n",
      "seed=\t [0.19764459 0.03596475 0.00927308 0.36674591 0.19362442 0.50362833\n",
      " 0.13141981 0.62675898] \tEI= 0.10301918506545028\n",
      "Suggested next query point (raw input space): 0.122641-0.153980-0.162409-0.045605-1.000000-0.536662-0.260830-0.252219\n",
      "Expected Improvement at this point (normalized): 0.10301918709500162\n",
      "GP predicted mean at this point (original y scale): [9.99260829]\n",
      "GP predicted stddev at this point (original y scale): [0.05233183]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel as C, WhiteKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load initial data\n",
    "# ------------------------------------------------------------\n",
    "X = np.load(\"initial_inputs.npy\")        # shape (n0, d)\n",
    "y = np.load(\"initial_outputs.npy\")       # shape (n0,)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Append new information\n",
    "# ------------------------------------------------------------\n",
    "X = np.append(X,[[0.060280, 0.000000, 0.134972, 0.000000, 1.000000, 0.404336, 0.057764, 0.516640]], axis=0)  # Append week1 inputs\n",
    "y = np.append(y, 9.8814618316)         # Append week1 outputs\n",
    "\n",
    "# Save the updated data\n",
    "np.save(\"updated_inputs_PW1.npy\", X)\n",
    "np.save(\"updated_outputs_PW1.npy\", y)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Normalise inputs and outputs\n",
    "# ------------------------------------------------------------\n",
    "x_scaler = StandardScaler()\n",
    "Xn = x_scaler.fit_transform(X)\n",
    "\n",
    "y_mean = y.mean()\n",
    "y_std = y.std() if y.std() > 0 else 1.0\n",
    "yn = (y - y_mean) / y_std                 # GP works better with normalized target\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Fit a Gaussian Process surrogate\n",
    "# ------------------------------------------------------------\n",
    "d = X.shape[1]\n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=np.ones(d),\n",
    "                                      length_scale_bounds=(1e-10, 1e10),\n",
    "                                      nu=2.5)\n",
    "kernel += WhiteKernel(noise_level=1e-6,\n",
    "                      noise_level_bounds=(1e-10, 1e1))\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              normalize_y=False,\n",
    "                              n_restarts_optimizer=10,\n",
    "                              random_state=0)\n",
    "gp.fit(Xn, yn)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Define Expected Improvement acquisition (for maximization)\n",
    "# ------------------------------------------------------------\n",
    "f_best = yn.max()\n",
    "xi = 0.01     # exploration parameter\n",
    "\n",
    "def predict_raw(x_raw):\n",
    "    \"\"\"Predict mean and std in normalized GP space for a raw input x_raw.\"\"\"\n",
    "    x = np.atleast_2d(x_raw)\n",
    "    xn = x_scaler.transform(x)\n",
    "    mu, sigma = gp.predict(xn, return_std=True)\n",
    "    return mu.ravel(), sigma.ravel()\n",
    "\n",
    "def expected_improvement_raw(x_raw, xi=xi):\n",
    "    \"\"\"Compute EI for a raw input x_raw.\"\"\"\n",
    "    mu, sigma = predict_raw(x_raw)\n",
    "    sigma = np.maximum(sigma, 1e-9)       # avoid division by zero\n",
    "    z = (mu - f_best - xi) / sigma\n",
    "    ei = (mu - f_best - xi) * norm.cdf(z) + sigma * norm.pdf(z)\n",
    "    #print (\"x_raw=\", x_raw, \"mu=\", mu, \"sigma=\", sigma,\"ei=\",ei)\n",
    "    return ei.ravel()[0]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Search for the next query point\n",
    "# ------------------------------------------------------------\n",
    "# Domain is assumed to be [0,1]^d (based on inspection of initial data)\n",
    "bounds = [(0.0, 1.0)] * d\n",
    "\n",
    "# Global random search to find good seeds\n",
    "n_seeds = 500\n",
    "rng = np.random.default_rng(1)\n",
    "candidates = rng.uniform(0.0, 1.0, size=(n_seeds, d))\n",
    "#Central limit theorm\n",
    "\n",
    "print (candidates.shape)\n",
    "ei_vals = np.array([expected_improvement_raw(c) for c in candidates])\n",
    "best_idx = np.argmax(ei_vals)\n",
    "print (\"first point ei_vals[\",best_idx,\"]=\", ei_vals[best_idx])\n",
    "\n",
    "# Take top few seeds for local optimisation\n",
    "seed_points = candidates[np.argsort(-ei_vals)[:10]]\n",
    "print (\"seed_points=\\n\", seed_points)\n",
    "\n",
    "best_x = None\n",
    "best_val = -1.0\n",
    "for s in seed_points:\n",
    "    res = minimize(lambda xx: -expected_improvement_raw(xx),\n",
    "                   x0=s,\n",
    "                   bounds=bounds,\n",
    "                   method=\"L-BFGS-B\",\n",
    "                   options={'maxiter':300})\n",
    "    if res.success:\n",
    "        val = -res.fun\n",
    "        print ( \"seed=\\t\", s, \"\\tEI=\", val)\n",
    "        #visualize_iteration(Xn, seed_points, best_x)\n",
    "        if val > best_val:\n",
    "            best_val = val\n",
    "            best_x = res.x.copy()\n",
    "            print ( \"best_x=\\t\", best_x, \"\\tEI=\", val )\n",
    "        \n",
    "        \n",
    "\n",
    "# Fallback if optimizer fails\n",
    "if best_x is None:\n",
    "    best_x = candidates[best_idx]\n",
    "    best_val = ei_vals[best_idx]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Report results\n",
    "# ------------------------------------------------------------\n",
    "suggested_point = np.atleast_1d(best_x)\n",
    "mu_s, sigma_s = predict_raw(suggested_point.reshape(1, -1))\n",
    "\n",
    "# Convert mean/std back to original y-scale\n",
    "mu_orig = mu_s * y_std + y_mean\n",
    "sigma_orig = sigma_s * y_std\n",
    "next_query = \"-\".join([f\"{xi:.6f}\" for xi in suggested_point])\n",
    "\n",
    "print(\"Suggested next query point (raw input space):\", next_query)\n",
    "print(\"Expected Improvement at this point (normalized):\", best_val)\n",
    "print(\"GP predicted mean at this point (original y scale):\", mu_orig)\n",
    "print(\"GP predicted stddev at this point (original y scale):\", sigma_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
