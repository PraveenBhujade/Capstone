{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "l87YfqG-ua5r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original candidates= (500, 6)\n",
      "Reduced candidates to 222 promising ones using SVM.\n",
      "Reduced candidates= (222, 6)\n",
      "first point ei_vals[ 61 ]= 0.0038755914121805825\n",
      "seed_points=\n",
      " [[0.04179161 0.10815954 0.51877912 0.25248938 0.28553513 0.74146953]\n",
      " [0.15138617 0.02850641 0.8662415  0.32973822 0.52113121 0.78725794]\n",
      " [0.15134593 0.04806967 0.43582599 0.21565299 0.47825274 0.82019648]\n",
      " [0.08054686 0.37115249 0.40375614 0.51302692 0.35142922 0.73466979]\n",
      " [0.37502874 0.27413178 0.68273606 0.29779484 0.36765987 0.72391271]\n",
      " [0.11717227 0.26873358 0.33643323 0.88592358 0.25074066 0.68187264]\n",
      " [0.24372164 0.29458141 0.95708403 0.36201606 0.28897611 0.72001112]\n",
      " [0.48050616 0.28141192 0.71281495 0.3820169  0.42517713 0.81624986]\n",
      " [0.20140189 0.45372918 0.25293035 0.20711901 0.36779487 0.80220494]\n",
      " [0.62814318 0.34820984 0.81076953 0.13730046 0.46254633 0.84077602]]\n",
      "seed=\t [0.04179161 0.10815954 0.51877912 0.25248938 0.28553513 0.74146953] \tEI= 0.06440010085616427\n",
      "best_x=\t [0.         0.16642896 0.51877912 0.25248938 0.38138155 0.74662412] \tEI= 0.06440010085616427\n",
      "seed=\t [0.15138617 0.02850641 0.8662415  0.32973822 0.52113121 0.78725794] \tEI= 0.06440009964225471\n",
      "seed=\t [0.15134593 0.04806967 0.43582599 0.21565299 0.47825274 0.82019648] \tEI= 0.06440010131246887\n",
      "best_x=\t [0.         0.1664293  0.43582599 0.21565304 0.38138153 0.74662416] \tEI= 0.06440010131246887\n",
      "seed=\t [0.08054686 0.37115249 0.40375614 0.51302692 0.35142922 0.73466979] \tEI= 0.06440009594582403\n",
      "seed=\t [0.37502874 0.27413178 0.68273606 0.29779484 0.36765987 0.72391271] \tEI= 0.06440010022021225\n",
      "seed=\t [0.11717227 0.26873358 0.33643323 0.88592358 0.25074066 0.68187264] \tEI= 0.06440008434248624\n",
      "seed=\t [0.24372164 0.29458141 0.95708403 0.36201606 0.28897611 0.72001112] \tEI= 0.06440009917416327\n",
      "seed=\t [0.48050616 0.28141192 0.71281495 0.3820169  0.42517713 0.81624986] \tEI= 0.06440009880924097\n",
      "seed=\t [0.20140189 0.45372918 0.25293035 0.20711901 0.36779487 0.80220494] \tEI= 0.06440010140959809\n",
      "best_x=\t [0.         0.16642946 0.25293035 0.20714227 0.38138151 0.74662417] \tEI= 0.06440010140959809\n",
      "seed=\t [0.62814318 0.34820984 0.81076953 0.13730046 0.46254633 0.84077602] \tEI= 0.06440010209784455\n",
      "best_x=\t [0.         0.16642919 0.81076953 0.13730318 0.38138147 0.74662416] \tEI= 0.06440010209784455\n",
      "Suggested next query point (raw input space): 0.000000-0.166429-0.810770-0.137303-0.381381-0.746624\n",
      "Expected Improvement at this point (normalized): 0.06440010209784455\n",
      "GP predicted mean at this point (original y scale): [2.30008523]\n",
      "GP predicted stddev at this point (original y scale): [0.08995944]\n",
      "This visualization works only for 2D input data.\n",
      "SVM visualisation works only for 2-D inputs.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel as C, WhiteKernel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load initial data\n",
    "# ------------------------------------------------------------\n",
    "X = np.load(\"initial_inputs.npy\")        # shape (n0, d)\n",
    "y = np.load(\"initial_outputs.npy\")       # shape (n0,)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Append new information\n",
    "# ------------------------------------------------------------\n",
    "X = np.append(X,[[0.000000, 0.246841, 0.408148, 0.217147, 0.377534, 0.746590]], axis=0)  # Append week1 inputs\n",
    "y = np.append(y, 2.302777955923556)         # Append week1 outputs\n",
    "\n",
    "X = np.append(X,[[0.000000, 0.181575, 0.435826, 0.062960, 0.361632, 0.858542]], axis=0)  # Append week2 inputs\n",
    "y = np.append(y, 1.3276855486043753)          # Append week2 outputs\n",
    "\n",
    "# Save the updated data\n",
    "np.save(\"updated_inputs_PW2.npy\", X)\n",
    "np.save(\"updated_outputs_PW2.npy\", y)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Normalise inputs and outputs\n",
    "# ------------------------------------------------------------\n",
    "x_scaler = StandardScaler()\n",
    "Xn = x_scaler.fit_transform(X)\n",
    "\n",
    "y_mean = y.mean()\n",
    "y_std = y.std() if y.std() > 0 else 1.0\n",
    "yn = (y - y_mean) / y_std                 # GP works better with normalized target\n",
    "\n",
    "\n",
    "def visualize_iteration(Xn, seed_points, suggested_point):\n",
    "    \"\"\"\n",
    "    Simple 2D visualization of current iteration:\n",
    "    - Xn: existing normalized input data (n x 2)\n",
    "    - seed_points: candidate points used for local optimization (m x 2)\n",
    "    - suggested_point: final chosen query point (1 x 2)\n",
    "    \"\"\"\n",
    "    if Xn.shape[1] != 2:\n",
    "        print(\"This visualization works only for 2D input data.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(Xn[:, 0], Xn[:, 1], c='blue', label='Existing points', s=40, alpha=0.7)\n",
    "    plt.scatter(seed_points[:, 0], seed_points[:, 1], c='orange', label='Seed points', s=50, alpha=0.7, edgecolors='k')\n",
    "    plt.scatter(suggested_point[0], suggested_point[1], c='red', label='Suggested point', s=120, marker='*', edgecolors='k')\n",
    "\n",
    "    plt.title(\"Bayesian Optimization Progress (2D)\")\n",
    "    plt.xlabel(\"Feature 1 (normalized)\")\n",
    "    plt.ylabel(\"Feature 2 (normalized)\")\n",
    "    #plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_svm(Xn, yn, candidates_raw, good_candidates_raw,\n",
    "                  suggested_point, svm_clf, x_scaler):\n",
    "    \"\"\"\n",
    "    Plot the SVM decision boundary together with:\n",
    "      • all random candidates (gray)\n",
    "      • candidates kept by SVM (orange)\n",
    "      • existing data (blue)\n",
    "      • final suggestion (red star)\n",
    "    \"\"\"\n",
    "    if Xn.shape[1] != 2:\n",
    "        print(\"SVM visualisation works only for 2-D inputs.\")\n",
    "        return\n",
    "\n",
    "    # Create a dense grid for the contour\n",
    "    h = 0.01\n",
    "    x_min, x_max = Xn[:,0].min()-0.2, Xn[:,0].max()+0.2\n",
    "    y_min, y_max = Xn[:,1].min()-0.2, Xn[:,1].max()+0.2\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "    Z = svm_clf.decision_function(grid)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    plt.figure(figsize=(9,7))\n",
    "    # Decision boundary\n",
    "    plt.contourf(xx, yy, Z, levels=[-np.inf,0,np.inf],\n",
    "                 colors=['#FFDDDD','#DDFFDD'], alpha=0.3)\n",
    "    plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors='k')\n",
    "\n",
    "    # All random candidates\n",
    "    plt.scatter(candidates_raw[:,0], candidates_raw[:,1],\n",
    "                c='lightgray', s=15, alpha=0.6, label='All random candidates')\n",
    "\n",
    "    # Candidates kept by SVM\n",
    "    plt.scatter(good_candidates_raw[:,0], good_candidates_raw[:,1],\n",
    "                c='orange', s=40, edgecolor='k', label='SVM-filtered candidates')\n",
    "\n",
    "    # Existing points (colour-coded by class for reference)\n",
    "    median_y = np.median(yn)\n",
    "    colors = np.where(yn >= median_y, 'blue', 'cyan')\n",
    "    plt.scatter(Xn[:,0], Xn[:,1], c=colors, s=80,\n",
    "                edgecolor='k', label='Existing points (≥/ < median)')\n",
    "\n",
    "    # Suggested point\n",
    "    plt.scatter(suggested_point[0], suggested_point[1], c='red',\n",
    "                s=150, marker='*', edgecolor='k', label='Suggested point')\n",
    "\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.title(\"SVM Decision Boundary + Candidate Filtering\")\n",
    "    plt.xlabel(\"Feature 1 (norm.)\")\n",
    "    plt.ylabel(\"Feature 2 (norm.)\")\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Fit a Gaussian Process surrogate\n",
    "# ------------------------------------------------------------\n",
    "d = X.shape[1]\n",
    "kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=np.ones(d),\n",
    "                                      length_scale_bounds=(1e-5, 1e9),\n",
    "                                      nu=2.5)\n",
    "kernel += WhiteKernel(noise_level=1e-6,\n",
    "                      noise_level_bounds=(1e-15, 1e1))\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel,\n",
    "                              normalize_y=False,\n",
    "                              n_restarts_optimizer=10,\n",
    "                              random_state=0)\n",
    "gp.fit(Xn, yn)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Add SVM to classify promising regions\n",
    "# ------------------------------------------------------------\n",
    "if len(yn) > 1:  # need at least two points for classification\n",
    "    median_y = np.median(yn)\n",
    "    labels = (yn >= median_y).astype(int)\n",
    "    svm_clf = SVC(kernel='rbf', C=1.0)\n",
    "    svm_clf.fit(Xn, labels)\n",
    "else:\n",
    "    svm_clf = None\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Define Expected Improvement acquisition (for maximization)\n",
    "# ------------------------------------------------------------\n",
    "f_best = yn.max()\n",
    "xi = 0.01     # exploration parameter\n",
    "\n",
    "def predict_raw(x_raw):\n",
    "    \"\"\"Predict mean and std in normalized GP space for a raw input x_raw.\"\"\"\n",
    "    x = np.atleast_2d(x_raw)\n",
    "    xn = x_scaler.transform(x)\n",
    "    mu, sigma = gp.predict(xn, return_std=True)\n",
    "    return mu.ravel(), sigma.ravel()\n",
    "\n",
    "def expected_improvement_raw(x_raw, xi=xi):\n",
    "    \"\"\"Compute EI for a raw input x_raw.\"\"\"\n",
    "    mu, sigma = predict_raw(x_raw)\n",
    "    sigma = np.maximum(sigma, 1e-9)       # avoid division by zero\n",
    "    z = (mu - f_best - xi) / sigma\n",
    "    ei = (mu - f_best - xi) * norm.cdf(z) + sigma * norm.pdf(z)\n",
    "    #print (\"x_raw=\", x_raw, \"mu=\", mu, \"sigma=\", sigma,\"ei=\",ei)\n",
    "    return ei.ravel()[0]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Search for the next query point\n",
    "# ------------------------------------------------------------\n",
    "# Domain is assumed to be [0,1]^d (based on inspection of initial data)\n",
    "bounds = [(0.0, 1.0)] * d\n",
    "\n",
    "# Global random search to find good seeds\n",
    "n_seeds = 500\n",
    "rng = np.random.default_rng(1)\n",
    "# Need to decide where the random points needs to be\n",
    "candidates_raw = rng.uniform(0.0, 1.0, size=(n_seeds, d))\n",
    "\n",
    "\n",
    "print (\"Original candidates=\", candidates_raw.shape)\n",
    "good_candidates_raw = candidates_raw.copy()\n",
    "\n",
    "if svm_clf is not None:\n",
    "    candidates_n = x_scaler.transform(candidates_raw)\n",
    "    predicted_labels = svm_clf.predict(candidates_n)\n",
    "    good_idx = np.where(predicted_labels == 1)[0]\n",
    "    if len(good_idx) > 0:\n",
    "        good_candidates_raw = candidates_raw[good_idx]\n",
    "        print(f\"Reduced candidates to {len(good_candidates_raw)} promising ones using SVM.\")\n",
    "\n",
    "print (\"Reduced candidates=\", good_candidates_raw.shape)\n",
    "\n",
    "# ---- EI evaluation on the (possibly reduced) candidate set ----\n",
    "ei_vals = np.array([expected_improvement_raw(c) for c in good_candidates_raw])\n",
    "best_idx = np.argmax(ei_vals)\n",
    "print (\"first point ei_vals[\",best_idx,\"]=\", ei_vals[best_idx])\n",
    "\n",
    "# ---- Take top-10 seeds for local optimisation ----\n",
    "seed_points = good_candidates_raw[np.argsort(-ei_vals)[:10]]\n",
    "print (\"seed_points=\\n\", seed_points)\n",
    "\n",
    "best_x = None\n",
    "best_val = -1.0\n",
    "for s in seed_points:\n",
    "    res = minimize(lambda xx: -expected_improvement_raw(xx),\n",
    "                   x0=s,\n",
    "                   bounds=bounds,\n",
    "                   method=\"L-BFGS-B\",\n",
    "                   options={'maxiter':300})\n",
    "    if res.success:\n",
    "        val = -res.fun\n",
    "        print ( \"seed=\\t\", s, \"\\tEI=\", val)\n",
    "        #visualize_iteration(Xn, seed_points, best_x)\n",
    "        if val > best_val:\n",
    "            best_val = val\n",
    "            best_x = res.x.copy()\n",
    "            print ( \"best_x=\\t\", best_x, \"\\tEI=\", val )\n",
    "        \n",
    "        \n",
    "\n",
    "# Fallback if optimizer fails\n",
    "if best_x is None:\n",
    "    best_x = good_candidates_raw[best_idx]\n",
    "    best_val = ei_vals[best_idx]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Report results\n",
    "# ------------------------------------------------------------\n",
    "suggested_point = np.atleast_1d(best_x)\n",
    "mu_s, sigma_s = predict_raw(suggested_point.reshape(1, -1))\n",
    "\n",
    "# Convert mean/std back to original y-scale\n",
    "mu_orig = mu_s * y_std + y_mean\n",
    "sigma_orig = sigma_s * y_std\n",
    "next_query = \"-\".join([f\"{xi:.6f}\" for xi in suggested_point])\n",
    "\n",
    "print(\"Suggested next query point (raw input space):\", next_query)\n",
    "print(\"Expected Improvement at this point (normalized):\", best_val)\n",
    "print(\"GP predicted mean at this point (original y scale):\", mu_orig)\n",
    "print(\"GP predicted stddev at this point (original y scale):\", sigma_orig)\n",
    "\n",
    "# Visualise 1. Standard BO progress plot\n",
    "visualize_iteration(X, seed_points, best_x)\n",
    "\n",
    "# 2. SVM decision-boundary plot (only when SVM was trained)\n",
    "if svm_clf is not None:\n",
    "    visualize_svm(X, y,\n",
    "                  candidates_raw,\n",
    "                  good_candidates_raw,\n",
    "                  best_x,\n",
    "                  svm_clf,\n",
    "                  x_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
